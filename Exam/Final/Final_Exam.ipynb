{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (30 pts)\n",
    "\n",
    "Suppose we have data of movie ratings from Twitter stored in 3 files. The data was created from people who connected their IMDB profile with their Twitter accounts. Whenever they rated a movie on the IMDB website, an automated process generated a standard, well-structured tweet. \n",
    "\n",
    "Run the following code to import the datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "users = pd.read_csv(\"users.csv\", index_col=\"user_id\")\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "movies = pd.read_csv(\"movies.csv\", index_col=\"movie_id\", na_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part a - 5 pts\n",
    "\n",
    "In the DataFrame **movies**, the column \"movie_title\" contains both movie title and year. Based on this column, create two columns called \"Title\" and \"Year\" that contain only the title and year. \n",
    "\n",
    "**Hint:** \n",
    "* Each cell is a string whose last a few index always correspond to \"year\". \n",
    "* Think about sequence index and list comprehension.\n",
    "* Year should have type int, and title should have type string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part b - 5 pts\n",
    "\n",
    "According to the column \"Year\" you create in part a, for year from 2010 to 2020 (inclusive), which year has the most number of movies and which year has the least number of movies?\n",
    "\n",
    "**Note**: If you stuck on part a, the \"Title\" and \"Year\" columns are provided in file **title_year**. Run the code below to update your DataFrame. Keep in mind, you will lose the 5 pts in part a if you do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_year = pd.read_csv(\"title_year.csv\", index_col=\"movie_id\")\n",
    "movies = pd.concat([movies, title_year], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part c - 5 pts\n",
    "\n",
    "In the DataFrame **movies**, the column \"genres\" contains the genres of a particular movie. If a single movie belongs to more than one genre, the genres are separated by pipe characters ```\"|\"```. Based on the \"genres\" column, create a new column called \"genres_list\" that transform the cell in \"genres\" into a list of genres. \n",
    "\n",
    "For example, for the first movie, the cell value for the \"genres\" column is ```Action|Horror```. Then, it should be ```[\"Action\", \"Horror\"]``` for the new created \"Genres_list\" column. Similarly, for second movie, it should be should be ```[\"Comedy\", \"Fantasy\", \"Romance\"]``` for the new created \"Genres_list\" column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part d - 5 pts\n",
    "\n",
    "Run the codes below to join three datasets and assign to variable name **ratings1**. Use **ratings1**, create a barplot that shows the frequency of different ratings for all the ```Action``` movies. In the barplot, the x-axis should be the different ratings, e.g. 5, 6, 7, 8 and etc; the y-axis should give the number of users that gave that ratings (If you decide to use a horizontal version, the values in x and y axis will be switched).\n",
    "\n",
    "**Note**: If you stuck on part c, the \"genres_list\" column is provided in file **genres_list.csv**. Run the codes below to update your DataFrame **movies** before joining with other 2 datasets. Keep in mind, you will lose the 5 pts in part c if you do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_list = pd.read_csv(\"genres_list.csv\", index_col=\"movie_id\")\n",
    "movies = pd.concat([movies, genres_list], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1 = ratings.join(users, on = \"user_id\").join(movies, on = \"movie_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part e - 10 pts\n",
    "\n",
    "write a query function named ```query_movie``` that takes the id of a particular movie as input and return a dictionary with keys: Title, Year, Genres, Number of Ratings, Average Ratings and their corresponding values as values.\n",
    "\n",
    "* Generes should be in the list form.\n",
    "* Number of Ratings is how many users have rated the movie.\n",
    "* Average Ratings is average rating score of the movie.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the followings to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'The Hobbit: An Unexpected Journey',\n",
       " 'Year': 2012,\n",
       " 'Genres': \"['Adventure', 'Family', 'Fantasy']\",\n",
       " 'Number of Ratings': 758,\n",
       " 'Average Ratings': 7.881266490765172}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_movie(903624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Rise of the Guardians',\n",
       " 'Year': 2012,\n",
       " 'Genres': \"['Animation', 'Action', 'Adventure', 'Comedy', 'Family', 'Fantasy']\",\n",
       " 'Number of Ratings': 239,\n",
       " 'Average Ratings': 7.606694560669456}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_movie(1446192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Extracted',\n",
       " 'Year': 2012,\n",
       " 'Genres': \"['Drama', 'Sci-Fi']\",\n",
       " 'Number of Ratings': 25,\n",
       " 'Average Ratings': 7.08}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_movie(1757746)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 (20 pts)\n",
    "\n",
    "For each of the following two parts, you need to conduct a hypothesis test to test the claim. When conducting the test, please use the following procedures:\n",
    "\n",
    "1. Formulate your null and alternative hypothesis.\n",
    "2. Decide which test is appropriate.\n",
    "3. Check if the assumption for the test you chose in step 2 is satisfied. If not, check the assumption.\n",
    "4. Calculate the test statisitic (Z or t score) and the p-value.\n",
    "5. Make a decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part a - 10 pts\n",
    "\n",
    "Suppose a study was designed to see if there is any difference in the social attitudes involving twenty sets of twins. To test te claim, one of the twins from each set was randomly assigned to live in a foreign country for 1 year, while the other stayed at home. The data can be found in the file **twins.csv**. Sample1 and Sample2 show the overall scores on social behavior from a questionnaire for the stay-home and live-abroad twins.\n",
    "\n",
    "Conduct an appropriate test at the $\\alpha = 0.01$ level of significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part b - 10 pts\n",
    "\n",
    "An experiment was taken to measure the effects of ozone. A group of 22 70-day-old rats\n",
    "were kept in an ozone environment for 7 days and their weight gains were recorded.\n",
    "Another group of 31 rats of a similar age were kept in an ozone-free environment for 7\n",
    "days and their weight gains were recorded. The data is given in file **ratweight.csv**.\n",
    "\n",
    "Is there a significant difference in the weight gain between group? Conduct a two-sided test to test at $\\alpha=0.1$ level of significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 (25 pts)\n",
    "\n",
    "In the previous homework, we have seen the standard Cauchy distribution has the following pdf (f):\n",
    "\n",
    "$$f(x) = \\frac{1}{\\pi(1+x^2)}, \\text{ for }  x\\in \\mathbb{R}.$$\n",
    "\n",
    "The distribution function (F) of Cauchy distribution is given by:\n",
    "\n",
    "$$F(x) = \\frac{1}{2}+\\frac{1}{\\pi}arc tan\\left(x\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part a - 5 pts\n",
    "\n",
    "Using the distribution function given above, write down its inverse function $F^{-1}(u)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part b - 10 pts\n",
    "\n",
    "Using the inversion method we covered in the class, and assuming we can generate $U\\sim Uniform(0,1)$ (use ```random.uniform()``` from numpy), write a function **random_cauchy** that generate random variable from the standard Cauchy distribution.\n",
    "\n",
    "**Note**: \n",
    "1. Your function does not have to have an input, but it needs to return a standard Cauchy random variable as output.\n",
    "2. In your function, you should not use any form of random.cauchy function from other package. But you are welcome to use them to check if your function is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part c - 10 pts\n",
    "\n",
    "Write a function **random_cauchy1** that generate random variable from the standard Cauchy distribution assuming the explicit form of $F^{-1}$ is **not given**. In this case, you need to eveluate $F^{-1}(u)$ numerically. Again, assume we can generate $U\\sim Uniform(0,1)$ (use ```random.uniform()``` from numpy)\n",
    "\n",
    "**Note**: \n",
    "1. Your function does not have to have an input, but it needs to return a Cauchy random variable as output.\n",
    "2. In your function, you should not use any form of random.cauchy function from other package. But you are welcome to use them to check if your function is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 (25 pts)\n",
    "\n",
    "In the lecture, we discussed how to generate normal random variable using the Laplace distribution. In this problem, we will see how to generate normal random variable using the rejection method and the standard Cauchy distribution.\n",
    "\n",
    "In this context, since we want to generate random variable from standard normal distribution, so we have the target density $f$\n",
    "\n",
    "$$f(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}, x\\in \\mathbb{R}.$$\n",
    "\n",
    "The instrumental density function $g$ is\n",
    "\n",
    "$$g(x) = \\frac{1}{\\pi(1+x^2)}, x\\in \\mathbb{R}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part a - 5 pts\n",
    "\n",
    "To make the rejection method work, we need to find a constant $c$, such that\n",
    "\n",
    "$$f(x) \\le cg(x) \\text{ for all } x \\in \\mathbb{R}.$$\n",
    "\n",
    "Also, we mentioned we want to specify $c$ such that:\n",
    "\n",
    "$$c = \\text{sup}_x \\frac{f(x)}{g(x)}.$$\n",
    "\n",
    "Verify that $c = \\sqrt{\\frac{2\\pi}{e}}\\approx 1.520347$.\n",
    "\n",
    "**Note**: You can do this analytically or numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part b - 10 pts\n",
    "\n",
    "Using $c$ you find in part a and ```randon_cauchy``` you wrote in Problem 3, write a function to implement the rejection method to generate a standard normal random variable. Again, assume we can generate $U\\sim Uniform(0,1)$ (use ```random.uniform()``` from numpy)\n",
    "\n",
    "**Note**: \n",
    "1. Your function does not have to have an input, but it needs to return a standard nornal random variable as output.\n",
    "2. In your function, you should not use any form of random.normal function from other package. But you are welcome to use them to check if your function is correct.\n",
    "3. In case you stuck on Problem 3, you can use ```random.standard_cauchy(size = 1)``` function from numpy package to get a random variable from the standard Cauchy distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part c - 10 pts\n",
    "\n",
    "Generate 5000 standard normal random variable using the function you defined in part b. Generate another 5000 standard normal random variable using ```np.random.normal```. Make 2 histograms overlay with each other to see if they are close.\n",
    "In addition, generate a normal qq plot using the 5000 normal random variables from your function. Comment on the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
